<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content="Section by Andrei Frumusanu Although the Willow Cove core doesnt bring all that many improvements on the actual core microarchitecture, one big update for the design is the new memory subsystem thanks to a quite significant change in the caches of the design."><meta name=generator content="Hugo 0.98.0"><meta name=robots content="index,follow,noarchive"><title>Cache Architecture: The Effect of Increasing L2 and L3 &#183;</title><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css><!--[if lte IE 8]><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css><![endif]--><!--[if gt IE 8]><!--><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css><!--<![endif]--><!--[if lte IE 8]><link rel=stylesheet href=https://assets.cdnweb.info/hugo/blackburn/css/side-menu-old-ie.css><![endif]--><!--[if gt IE 8]><!--><link rel=stylesheet href=https://assets.cdnweb.info/hugo/blackburn/css/side-menu.css><!--<![endif]--><link rel=stylesheet href=https://assets.cdnweb.info/hugo/blackburn/css/blackburn.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css2?family=Raleway&display=swap" rel=stylesheet type=text/css><script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/styles/androidstudio.min.css><script async src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/highlight.min.js></script>
<script>hljs.initHighlightingOnLoad()</script><link rel="shortcut icon" href=./img/favicon.ico type=image/x-icon></head><body><div id=layout><a href=#menu id=menuLink class=menu-link><span></span></a><div id=menu><a class="pure-menu-heading brand" href=./index.html>JoltBlog</a><div class=pure-menu><ul class=pure-menu-list><li class=pure-menu-item><a class=pure-menu-link href=./index.html><i class="fa fa-home fa-fw"></i>Home</a></li><li class=pure-menu-item><a class=pure-menu-link href=./post/index.html><i class="fa fa-list fa-fw"></i>Posts</a></li><li class=pure-menu-item><a class=pure-menu-link href=./sitemap.xml><i class="fa fa-user fa-fw"></i>Sitemap</a></li><li class=pure-menu-item><a class=pure-menu-link href=./index.xml><i class="fa fa-phone fa-fw"></i>RSS</a></li></ul></div><div class="pure-menu social"><ul class=pure-menu-list></ul></div><div><div class=small-print><small>&copy; 2022. All rights reserved.</small></div><div class=small-print><small>Built with&nbsp;<a href=https://gohugo.io/ target=_blank>Hugo</a></small>
<small>Theme&nbsp;<a href=https://github.com/yoshiharuyamashita/blackburn target=_blank>Blackburn</a></small></div></div></div><div id=main><div class=header><h1>Cache Architecture: The Effect of Increasing L2 and L3</h1><h2>Section by Andrei Frumusanu Although the Willow Cove core doesnt bring all that many improvements on the actual core microarchitecture, one big update for the design is the new memory subsystem thanks to a quite significant change in the caches of the design.</h2></div><div class=content><div class=post-meta><div><i class="fa fa-calendar fa-fw"></i>
<time>01 Jan 0001, 00:00</time></div></div><p>Section by Andrei Frumusanu</p><h2>Cache Architecture: The Effect of Increasing L2 and L3</h2><p>Although the Willow Cove core doesn’t bring all that many improvements on the actual core microarchitecture, one big update for the design is the new memory subsystem thanks to a quite significant change in the caches of the design.</p><p>Intel here has made some big changes in the L2 caches as well as the L3 cache slices: they’ve both grown considerably bigger and have had their cache line exclusivity altered.</p><table border=0 width=95%><tbody><tr class=tgrey><td colspan=7>Core Cache Comparison</td></tr><tr class=tlblue><td>Willow<br>Cove</td><td><i>AnandTech</i></td><td>Sunny<br>Cove</td><td>Cannon<br>Lake</td><td>Skylake</td><td>AMD<br>Zen 2</td></tr><tr><td><strong>48 KB<br>12-way</strong></td><td class=tlgrey>L1-D</td><td>48 KB<br>12-way</td><td>32 KB<br>8-way</td><td>32 KB<br>8-way</td><td>32 KB<br>8-way</td></tr><tr><td>32 KB<br>8-way</td><td class=tlgrey>L1-I</td><td>32 KB<br>8-way</td><td>32 KB<br>8-way</td><td>32 KB<br>8-way</td><td>32 KB<br>8-way</td></tr><tr><td><strong>1280 KB<br>20-way</strong></td><td class=tlgrey>L2</td><td>512 KB<br>8-way</td><td>256 KB<br>4-way</td><td>256 KB<br>4-way</td><td>512 KB<br>8-way</td></tr><tr><td><strong>3 MB</strong><br>(&lt;=12MB)<br>12-way</td><td class=tlgrey>L3/core<br>(Max. Total)</td><td>2 MB<br>(&lt;=8MB)<br>16-way</td><td>2 MB<br>(&lt;=8MB)<br>16-way</td><td>2 MB<br>(&lt;=20MB)<br>16-way</td><td><strong>4 MB<br>(&lt;=16MB)<br>16-way</strong></td></tr><tr><td>2304</td><td class=tlgrey>uOp Cache</td><td>2304</td><td>1536</td><td>1536</td><td><strong>4096</strong></td></tr></tbody></table><p>The L1-D and L1-I caches on Willow Cove remain the same as the predecessor Sunny Cove design, which means they retain their 48KB 12-way associative designs for the data cache, respectively 32KB 8-way associative design for the instruction cache.</p><p>Where things differ significantly is in the L2. This time around Intel has completely redesigned this part of the core and has increased the capacity by 150% by increasing it from 512KB to 1280KB. Furthermore, the actual usable capacity has increased even more between generations as the new design now moves from being inclusive of the L1 caches, to a non-inclusive design.</p><p>Compromises that had been made when increasing the cache by this great of an amount is in the associativity, which now increases from 8-way to a 20-way, which likely decreases conflict misses for the structure.</p><p>On the L3 side, there’s also been a change in the microarchitecture as the cache slice size per core now increases from 2MB to 3MB, totalling to 12MB for a 4-core Tiger Lake design. Here Intel actually reduced the associativity from 16-way to 12-way, likely increasing cache line conflict misses and decreasing access parallelism.</p><p align=center><a href=# id=lat1><img alt id=lat1pic src=https://cdn.statically.io/img/images.anandtech.com/doci/16084/TGL-log.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>When looking at the i7-1185G7 in our custom latency test tool, we immediately note the cache structure changes when comparing the results to a previous generation design such as the Ice Lake based i7-1065G7.</p><p>First thing to note here about the results is the frequency of the cores as well as the system’s DRAM configurations: The Tiger Lake part clocked up to 4800MHz and featured LPDDR4X-4266 with 36-39-39 timings, while the Ice Lake figures were measured on a Surface Laptop 3, clocking at 3900MHz and LPDDR4X-3733 32-34-34.</p><p>On the L1 side of things as expected we don’t see much changes in latency beyond the clock frequency increase which brings access times down from 1.3ns to 1.04ns.</p><p>Moving onto the L2 cache is where things become interesting. Absolute access time figures go down from 3.3 to 2.9ns, but the Willow Cove core now extends this access time across a deeper depth up to 1.25MB – exactly as we’d expect given the cache’s larger structure this generation.</p><p>The access latencies don’t extend exactly to 12MB because starting from 8MB we’re exceeding the coverage of the L2 TLB at which point the core has to page-walk, incurring heavier latency penalties.</p><p>Intel hasn’t changed the TLBs this generation, still maintaining a 64-page L1 TLB which means that starting from 256KB depth (at 4KB pages), we’re seeing an increase in access times for access patterns which miss the first level TLB.</p><p>On the L3 we’re getting some interesting results which are both positive and negative. The positive thing of course is the vastly increased depth of the cache which now sees extended good access latencies up around the 10-12MB mark. What’s seemingly not so great is the fact that the absolute latency figures here aren’t really any different to Ice Lake, ending up nearly identical even though the Tiger Lake design clocks up to 23% higher in frequency. This is a sign that the cycle-access latencies of the design have gone up quite a bit this generation.</p><p>On deeper depths reaching DRAM, things are massively improved for the new Tiger Lake design: Full random access at an equal 160MB depth here in the graphs improve from 130ns to 98ns. Admittedly, we’re using different DRAM configurations between the two test platforms and the Tiger Lake system is using 14% higher clocked memory, but it does have worse timings. The actual latency improvements are well beyond the theoretical DRAM access latency difference, so what I think is happening here is that Intel has made some improvements to their memory subsystem and memory controllers.</p><p>We’re seeing a slight change in the access pattern latencies compared to Ice Lake, especially in the “R per R page” pattern which remains within a single memory page before moving onto the next, with the access latencies being 30% better than on Ice Lake. This does point out to some actual structural changes on the memory controller side, as otherwise the prefetcher behaviour at least doesn’t see any changes at all- with things being pretty much similar to back to what we’ve seen on Skylake.</p><p>What’s also interesting for the new design is that straightforward linear streaming patterns have seen a slight degradation, increasing from 3.516ns to 4.277ns on the new core. This is likely a side-effect of the added cache cycles in the lower level caches of the new Willow Cove core.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/16084/TGL-cycles.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Translating the latency graph from nanoseconds to core cycles, we’re seeing the generational structural changes between the Sunny Cove and Willow Cove designs.&nbsp;</p><table border=0 width=85%><tbody readability=1><tr class=tgrey readability=2><td colspan=7>Core Cache Latency (in core cycles)</td></tr><tr class=tlblue><td>Willow Cove</td><td><i>AnandTech</i></td><td>Sunny Cove</td><td>Cannon<br>Lake</td><td>Skylake</td><td>&nbsp;</td><td>AMD<br>Zen 2</td></tr><tr><td>5</td><td class=tlgrey>L1</td><td>5</td><td>4</td><td>4</td><td>&nbsp;</td><td>4</td></tr><tr><td><strong>14</strong></td><td class=tlgrey>L2</td><td>13</td><td>12</td><td>~12</td><td>&nbsp;</td><td>12</td></tr><tr><td><strong>39-45</strong></td><td class=tlgrey>L3</td><td>30-36</td><td>&nbsp;</td><td>26-37</td><td>&nbsp;</td><td>34</td></tr></tbody></table><p>The L1D cache remains the same at 5 cycles latency, which is still a 1-cycle degradation over Skylake cores.</p><p>The L2 seemingly has gone up from 13 cycles to 14 cycles in Willow Cove, which isn’t all that bad considering it is now 2.5x larger, and its associativity has gone up. It’s interesting to contrast this against other similarly sized caches in the industry: Arm’s Neoverse N1 core has a 1MB cache coming in at 11-cycle latency, whilst their new X1 core shaves this down to 10 cycles. Of course, Intel’s designs clocks much higher, but the competitor’s design still would end up with better absolute access times.</p><p>The L3 cache cycle latency is a bit disappointing as we’re seeing essentially a +9 cycle degradation over the older design. This explains the previous access latencies which essentially just remained the same even though the core clocks in 23% higher.</p><p align=center><a href=# id=bw1><img alt id=bw1pic src=https://cdn.statically.io/img/images.anandtech.com/doci/16084/TGL-bw.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Finally, having a quick glance at the single-core bandwidth figures we’re looking if there’s been any significant structural changes in this aspect of the design.</p><p>On the L1 side of things, things are a bit odd as the figures don’t scale up as expected with the clock frequency, pure load and store bandwidth are indeed higher but the memory copy patterns are less than expected. In the L2 and L3 regions we can clearly see the increased depth of the caches. The L2 scales well with a near 19% increase in bandwidth which is in line with the clock uptick.</p><p>The L3 doesn’t scale that well as memory copies between cache lines here are only 5% faster than on Ice Lake, likely due to the increased access latencies of the caches.</p><p>In the DRAM region we’re actually seeing a large change in behaviour of the new microarchitecture, with vastly improved load bandwidth from a single core, increasing from 14.8GB/S to 21GB/s. Pure store bandwidth slightly goes down from 14.8GB/s to 13.5GB/s but that’s not quite important as a metric for x86 as the core first has to read out the memory before writing to it, as opposed to some of the non-temporal write optimisations we’ve seen from Arm processors.</p><p>More importantly, memory copies between cache lines and memory read-writes within a cache line have respectively improved from 14.8GB/s and 28GB/s to 20GB/s and 34.5GB/s. That’s a 35% improvement in copy bandwidth which is quite significant.</p><p>Overall, the new Willow Cove cores and the Tiger Lake memory subsystem seems sort of a mixed bag. The increased cache sizes are certainly welcome for workloads that have a larger memory-footprint; however, Intel’s L3 cache changes seem to have come with some larger compromises when it comes to latency. On the positive side, DRAM access latencies and bandwidth seem to have been drastically improved in the new design, and here it seems Intel made some good improvements in the fabric as well as the memory controllers of Tiger Lake.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH53fJdtZqKmpJq5bsDIoJyrZZyWuKZ50Z6top2nYrGmsc9mm6KulWKwsL7EZmhqrJhitKa6jm0%3D</p><h4><i class="fas fa-share-alt" aria-hidden=true></i>&nbsp;Share!</h4><ul class=share-buttons><li><a href="https://www.facebook.com/sharer/sharer.php?u=%2fintel-tiger-lake-review-deep-dive-core-11th-gen.html" target=_blank title="Share on Facebook"><i class="fab fa-facebook" aria-hidden=true></i><span class=sr-only>Share on Facebook</span></a></li>&nbsp;&nbsp;&nbsp;<li><a href="https://twitter.com/intent/tweet?source=%2fintel-tiger-lake-review-deep-dive-core-11th-gen.html" target=_blank title=Tweet><i class="fab fa-twitter" aria-hidden=true></i><span class=sr-only>Tweet</span></a></li>&nbsp;&nbsp;&nbsp;<li><a href="https://plus.google.com/share?url=%2fintel-tiger-lake-review-deep-dive-core-11th-gen.html" target=_blank title="Share on Google+"><i class="fab fa-google-plus" aria-hidden=true></i><span class=sr-only>Share on Google+</span></a></li>&nbsp;&nbsp;&nbsp;<li><a href="http://www.tumblr.com/share?v=3&u=%2fintel-tiger-lake-review-deep-dive-core-11th-gen.html" target=_blank title="Post to Tumblr"><i class="fab fa-tumblr" aria-hidden=true></i><span class=sr-only>Post to Tumblr</span></a></li>&nbsp;&nbsp;&nbsp;<li><a href="http://pinterest.com/pin/create/button/?url=%2fintel-tiger-lake-review-deep-dive-core-11th-gen.html" target=_blank title="Pin it"><i class="fab fa-pinterest-p" aria-hidden=true></i><span class=sr-only>Pin it</span></a></li>&nbsp;&nbsp;&nbsp;<li><a href="http://www.reddit.com/submit?url=%2fintel-tiger-lake-review-deep-dive-core-11th-gen.html" target=_blank title="Submit to Reddit"><i class="fab fa-reddit-alien" aria-hidden=true></i><span class=sr-only>Submit to Reddit</span></a></li></ul><style>ul.share-buttons{list-style:none;padding:0}ul.share-buttons li{display:inline}ul.share-buttons .sr-only{position:absolute;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px);padding:0;border:0;height:1px;width:1px;overflow:hidden}</style><div class="prev-next-post pure-g"><div class=pure-u-1-24 style=text-align:left><a href=./candice-king-2.html><i class="fa fa-chevron-left"></i></a></div><div class=pure-u-10-24><nav class=prev><a href=./candice-king-2.html>Candice King Age, Net Worth, Husband, Family and Biography (Updated 2023)</a></nav></div><div class=pure-u-2-24>&nbsp;</div><div class=pure-u-10-24><nav class=next><a href=./brucedropemoff-3.html>BruceDropEmOff Age, Net Worth, Girlfriend, Family and Biography (Updated 2023)</a></nav></div><div class=pure-u-1-24 style=text-align:right><a href=./brucedropemoff-3.html><i class="fa fa-chevron-right"></i></a></div></div></div></div></div><script src=https://assets.cdnweb.info/hugo/blackburn/js/ui.js></script>
<script src=https://assets.cdnweb.info/hugo/blackburn/js/menus.js></script>
<script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/banner.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>